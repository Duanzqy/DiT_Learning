# 项目概述

#### Motivation
1. 之前写的处理脚本效率低，且难以复用
2. 没找到好的开源处理框架
3. 组里目前都是根据任务各自写处理脚本，且大多通过特定条件筛选，缺少从视频质量方面过滤
4. 没有说明文档，上手较困难

#### 目标：
- 可复用，易于添加新的模块
- 说明文档完整，易于使用
- 多阶段、或者是不同用途
#### 多阶段：
1. 预处理，指对视频本身的基本性质做处理，例如：编解码、剔除字幕区域、剔除黑边区域、视频片段分割
2. 视频质量过滤，可从以下几个方面：
	- 技术质量、清晰度：[Dover](https://github.com/VQAssessment/DOVER)
	- 运动稳定性： [UniMatch](https://github.com/autonomousvision/unimatch)
	- 美学：[christophschuhmann/improved-aesthetic-predictor: CLIP+MLP Aesthetic Score Predictor](https://github.com/christophschuhmann/improved-aesthetic-predictor)
	- 光照
	- 其他根据实际需求添加
3. 条件过滤模块：根据任务需求，添加指定过滤模块
4. 生成额外信息，例如
	- SMPLX
	- [DWPose](https://github.com/ViTAE-Transformer/ViTPose)
	- caption
#### 具备功能：
1. 基本功能：
	- 日志
	- 断点重续
	- Debug
2. 效率：顺序处理、线程安全、批量处理
3. 用户使用：
	- 说明文档完整
	- 易于添加模块
4. 其他功能
	- 筛选统计

---
# 处理代码学习

## Filter Vids代码框架
- Filter Vids 代码框架：(Author: Yudong)
- 路径：/home/juyonggroup/shared3dv/dataset/shared_codes/FilterRawVids

##### 整体逻辑
- 主程序通过 `vid_paths = vid_paths[block_id::block_size]` 将待处理文件分块，然后同时执行多个程序实现并行
- 管线通过分配给不同任务的队列实现 “流水线并行”（按顺序串行），具体如下：
	- 先定义一串按顺序执行的任务（当前4个阶段：提帧、音频特征、帧分析、视听同步），为每个任务各建一个独立队列与单个线程；启动时把所有视频（及其保存目录信息）全部放进第一个任务的队列，第一个阶段线程取出一个视频处理成功后，将同一视频元组投递到下一个任务的队列，依次向后流动，因此不同视频可同时处在不同阶段形成“流水线并行”；每个阶段完成结果写入该视频目录下的 steps_success.json（成功为 True，失败为 False，已成功的阶段下次会被跳过），若某阶段失败则不会进入后续阶段，直到重新运行再次尝试

#### 主程序：main_vidlist_process.py
- 输入参数：
	- video_list: 待处理数据的路径文本文件（每行一个）
	- output_dir: 保存视频的根目录
	- block_size, block_id: 对 video_list 进行抽样处理的参数，用于并行
- 主要实现功能：
	1. 读取 video_list, 并且根据 block_size, block_id 进行分块得 vid_path，以此实现并行
	2. 对每个 vid_path 中的待处理视频路径，构建独立保存路径
	3. 调用 VideoProcessingPipeline() 对每个视频进行处理

#### VideoProcessingPipeline 核心处理管线
###### 初始化__init__(self):
- TASK_MAP: 任务名称 -> 处理器类(Class) 的哈希表，用于统一定义所需要执行的任务
- self.sequential_tasks: 按 TASK_MAP 的键值(key)，即任务名称顺序形成的列表，表示任务执行的顺序
- 由 TASK_MAP 构建两个映射，为每个任务创建：
	- 一个处理器实例 self.processors[task]
	- 一个队列 self.queues[task]（queue.Queue()）
	其中它们的键值都是任务名称
```python
self.processors = {task: constructor() for task, constructor in self.TASK_MAP.items()}
self.queues = {task: queue.Queue() for task in self.sequential_tasks}
```

###### 线程工作模型_work(self, task_name, task_idx):
1. 为 task_name 队列取 (file_path, save_dir, with_debug).
2. 若是第一个任务（task_idx=0）：
	- 创建保存目录
	- 若源视频不存在则报错并跳过（不向后续任务传递）。
3. 调用_process_task_for_item 执行当前任务，得返回 Bool 值
4. 如果成功 (True)，将同一个 (file_path, save_dir, with_debug) 放入下一个任务(task_idx+1)的队列
5. 调用 task_done()

###### 处理单个任务函数_process_task_for_item(self, task_name, task_idx, file_path, save_dir, with_debug):
**核心功能**：
1. 读写日志 json，实现断点重续、防止乱序（检测前一个任务是否完成）
2. 创建 debug 目录
3. 执行 处理类 processor()，返回 bool 值给_work()

###### 调用管线的主入口 run_pipeline(self, video_file_list, save_dir_list, with_debug=False)：
- 为每个任务起一个线程
- 将所有视频列表存入第一个任务的队列 (queue) 中
- 对每个任务队列执行`self.queues[task].join()` ，阻塞直到全部处理完成

**其中 join() 的作用**：
1. 每次往队列里 put() 一个元素，内部“未完成任务计数器”+1
2. 消费者线程处理完一个元素后，必须调用 queue.task_done()，计数器-1
3. 当计数器回到 0 时，之前阻塞在 queue.join() 的线程才会继续往下执行
即与之前_work()中的 task_done() 相对应